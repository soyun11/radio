#!/usr/bin/env python3
import torch
from faster_whisper import WhisperModel
import os
import sys
import re

# ============================================================
# 1. Timestamp Formatter
# ============================================================
def format_timestamp(seconds: float) -> str:
    hrs = int(seconds // 3600)
    mins = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int(round((seconds - int(seconds)) * 1000))
    return f"{hrs:02}:{mins:02}:{secs:02},{millis:03}"

# ============================================================
# 2. Hard Filter (í™˜ê° ë°©ì§€ìš© ê°•ë ¥ í•„í„°)
# ============================================================
def is_hallucination(text):
    """
    Whisper ëª¨ë¸ì´ ìŒì•…/ë¬´ìŒ êµ¬ê°„ì—ì„œ ìì£¼ ë±‰ëŠ” í™˜ê°(Hallucination) í‚¤ì›Œë“œ í•„í„°ë§
    """
    text = text.strip()
    
    # 1. ë„ˆë¬´ ì§§ê±°ë‚˜ íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš° ì‚­ì œ
    if len(text) < 2:
        return True
    
    # 2. ë¸”ë™ë¦¬ìŠ¤íŠ¸ (ë¼ë””ì˜¤/ìŒì•… í™˜ê° ì „ìš©)
    blacklist = [
        "í•œê¸€ìë§‰", "ìë§‰ by", "Subtitle",
        "ì‹œì²­í•´ ì£¼ì…”ì„œ", "êµ¬ë…ê³¼ ì¢‹ì•„ìš”", "ì•Œë¦¼ ì„¤ì •", "ì¢‹ì•„ìš”", "êµ¬ë…",
        "ë‹¤ìŒ ì£¼ì— ë§Œë‚˜ìš”", "ë‹¤ìŒ ì˜ìƒì—ì„œ"
    ]
    
    for word in blacklist:
        # ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  í¬í•¨ ì—¬ë¶€ í™•ì¸
        if word.lower() in text.lower():
            # ë¬¸ì¥ì´ ë„ˆë¬´ ì§§ì€ë°(10ê¸€ì ë¯¸ë§Œ) ì € ë‹¨ì–´ê°€ í¬í•¨ë˜ë©´ 100% í™˜ê°
            if len(text) < 15:
                return True
            # ë¬¸ì¥ì´ ê¸¸ë”ë¼ë„ 'MBC ë¼ë””ì˜¤ì…ë‹ˆë‹¤' ê°™ì´ ë”± ë–¨ì–´ì§€ë©´ í™˜ê°
            if text == word:
                return True

    # 3. ë°˜ë³µ ë¬¸ì í•„í„°ë§ (ì˜ˆ: ".......", "!!!!", "ìœ¼ìœ¼ìœ¼ìœ¼")
    if len(text) > 5 and len(set(text)) < 3:
        return True
    
    # 4. ë°˜ë³µ êµ¬ë¬¸ í•„í„°ë§ (ì˜ˆ: "í–‰ë³µí•˜ì„¸ìš” í–‰ë³µí•˜ì„¸ìš” í–‰ë³µí•˜ì„¸ìš”")
    if len(text) > 20:
        words = text.split()
        if len(words) > 4 and len(set(words)) < len(words) / 2:
            return True
        
    return False

# ============================================================
# 3. Main Execution
# ============================================================
if len(sys.argv) != 2:
    print("Usage: python whisper-direct.py <date_or_filepath>")
    print("Example 1: python whisper-direct.py 20260131")
    print("Example 2: python whisper-direct.py /path/to/audio.mp3")
    exit(1)

INPUT_ARG = sys.argv[1]

# ì…ë ¥ì´ ë‚ ì§œì¸ì§€ íŒŒì¼ ê²½ë¡œì¸ì§€ íŒë‹¨í•˜ì—¬ ê²½ë¡œ ì„¤ì •
if os.path.isfile(INPUT_ARG):
    # ì§ì ‘ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì€ ê²½ìš°
    AUDIO_FILE = INPUT_ARG
    BASE_DIR = os.path.dirname(os.path.dirname(AUDIO_FILE)) # ../../
    DATE = os.path.splitext(os.path.basename(AUDIO_FILE))[0]
    OUTPUT_DIR = os.path.join(os.path.dirname(AUDIO_FILE), "../transcript")
else:
    # ë‚ ì§œ(YYYYMMDD)ë§Œ ì…ë ¥ë°›ì€ ê²½ìš° (ê¸°ë³¸ ì„¤ì •)
    DATE = INPUT_ARG
    # â˜… ì£¼ì˜: ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ baechulsu ë˜ëŠ” jeongeunim ìˆ˜ì • í•„ìš” â˜…
    BASE_DIR = f"/mnt/home_dnlab/jhjung/radio/baechulsu/{DATE}"
    AUDIO_FILE = f"{BASE_DIR}/mp3/{DATE}.mp3"
    OUTPUT_DIR = f"{BASE_DIR}/transcript"

# ì¶œë ¥ í´ë” ìƒì„±
os.makedirs(OUTPUT_DIR, exist_ok=True)

OUTPUT_TEXT = f"{OUTPUT_DIR}/{DATE}.txt"
OUTPUT_SRT = f"{OUTPUT_DIR}/{DATE}.srt"

if not os.path.exists(AUDIO_FILE):
    print(f"âŒ Audio file not found: {AUDIO_FILE}")
    exit(1)

# ëª¨ë¸ ì„¤ì •
WHISPER_MODEL_SIZE = "large-v3"
LANGUAGE = "ko"
USE_VAD = True

print("ğŸš€ Loading faster-whisper model...")
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# ëª¨ë¸ ë¡œë“œ (float16 ì‚¬ìš©ìœ¼ë¡œ ì†ë„ ìµœì í™”)
model = WhisperModel(
    WHISPER_MODEL_SIZE,
    device=device,
    compute_type="float16"
)

print(f"\nâ–¶ Starting transcription for: {AUDIO_FILE}")
print(f"Model: {WHISPER_MODEL_SIZE} | Language: {LANGUAGE} | VAD: {USE_VAD}")

# ============================================================
# 4. Transcribe (íŠœë‹ëœ íŒŒë¼ë¯¸í„°)
# ============================================================
segments, info = model.transcribe(
    AUDIO_FILE,
    language=LANGUAGE,
    beam_size=5,
    best_of=5,
    
    # [VAD] 0.5ì´ˆ ì´ìƒì˜ ì¹¨ë¬µì€ ë¬´ì‹œ (Demucsë¡œ ìŒì•…ì´ ì§€ì›Œì§„ êµ¬ê°„ ìŠ¤í‚µìš©)
    vad_filter=USE_VAD,
    vad_parameters=dict(min_silence_duration_ms=500),


    # [ì¤‘ìš”] ì´ì „ ë¬¸ë§¥ ì°¸ì¡° ë„ê¸° (ìŒì•… êµ¬ê°„ ë°˜ë³µ ìƒì„± ë°©ì§€)
    condition_on_previous_text=False,

    # [ì¤‘ìš”] í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (í™˜ê° ì–µì œ)
    initial_prompt="ë¼ë””ì˜¤ ë°©ì†¡ì…ë‹ˆë‹¤. ìŒì•…ì„ ì œì™¸í•œ ëª¨ë“  ë°œí™”ë¥¼ ì „ì‚¬í•©ë‹ˆë‹¤.",

    # [íƒìƒ‰] ì¸ì‹ì´ ì˜ ì•ˆ ë  ë•Œ ì˜¨ë„ë¥¼ ë†’ì—¬ê°€ë©° ì¬ì‹œë„
    temperature=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],

    # [í•„í„°] ë°˜ë³µ íŒ¨ë„í‹°
    repetition_penalty=1.2,
    no_speech_threshold=0.6,
    
    word_timestamps=True
)

print("\nğŸ¤ Transcription Completed!")
print(f"Detected language: {info.language} ({info.language_probability:.2f})")
print(f"Duration: {info.duration:.2f} sec")

# ============================================================
# 5. Save Output
# ============================================================
print(f"\nğŸ’¾ Saving output...")

with open(OUTPUT_TEXT, "w", encoding="utf-8") as f_text, \
     open(OUTPUT_SRT, "w", encoding="utf-8") as f_srt:

    seg_idx = 1
    hallucination_count = 0

    for seg in segments:
        start = seg.start
        end = seg.end
        text = seg.text.strip()

        if not text:
            continue
            
        # í™˜ê° í•„í„°ë§
        if is_hallucination(text):
            hallucination_count += 1
            continue

        # TXT ì €ì¥
        f_text.write(f"[{format_timestamp(start)} â†’ {format_timestamp(end)}] {text}\n")

        # SRT ì €ì¥
        f_srt.write(f"{seg_idx}\n")
        f_srt.write(f"{format_timestamp(start)} --> {format_timestamp(end)}\n")
        f_srt.write(f"{text}\n\n")

        seg_idx += 1

print("\nğŸ‰ ALL DONE!")
print(f"Filtered {hallucination_count} hallucination segments.")
print(f"Check output files:\n  {OUTPUT_TEXT}\n  {OUTPUT_SRT}")