import os
import csv
import json
import argparse
import librosa
import numpy as np
from tqdm import tqdm

def extract_features(y, sr):
    if len(y) < 512:
        return [0.0] * 31
    try:
        rms = float(np.mean(librosa.feature.rms(y=y)))
        zcr = float(np.mean(librosa.feature.zero_crossing_rate(y=y)))
        centroid = float(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))
        bandwidth = float(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))
        flatness = float(np.mean(librosa.feature.spectral_flatness(y=y)))
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
        mfcc_mean = np.mean(mfcc, axis=1).tolist()
        mfcc_std = np.std(mfcc, axis=1).tolist()
        return [rms, zcr, centroid, bandwidth, flatness] + mfcc_mean + mfcc_std
    except:
        return [0.0] * 31

def sliding_window_from_buffer(y_sub, sr, window_sec=1.0):
    win_len = int(window_sec * sr)
    all_features = []
    if len(y_sub) <= win_len:
        return [extract_features(y_sub, sr)]
    for start in range(0, len(y_sub) - win_len + 1, win_len):
        window = y_sub[start:start+win_len]
        all_features.append(extract_features(window, sr))
    return all_features

#def process_date(date_str, out_base_dir):
def process_date(date_str):
    # ê²½ë¡œ ì„¤ì •
    input_base_dir = f"/mnt/home_dnlab/jhjung/radio/jeongeunim/{date_str}"
    output_base_dir = f"/mnt/home_dnlab/jhjung/radio/jeongeunim/{date_str}/transcript"
    #output_base_dir = f"/home/yslee/ad_detection/diarize/mbc-test/{date_str}"
    csv_file = os.path.join(input_base_dir, "transcript", f"{date_str}_with_speaker.csv")
    mp3_file = os.path.join(input_base_dir, "mp3", f"{date_str}.mp3")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    #os.makedirs(out_base_dir, exist_ok=True)
    out_file = os.path.join(output_base_dir, f"{date_str}_features.jsonl")
    #out_file = os.path.join(out_base_dir, f"{date_str}_features.jsonl")

    if not os.path.exists(csv_file):
        print(f"âŒ CSV ì—†ìŒ: {csv_file}")
        return
    if not os.path.exists(mp3_file):
        print(f"âŒ MP3 ì—†ìŒ: {mp3_file}")
        return

    print(f"ðŸš€ [{date_str}] ë¶„ì„ ì‹œìž‘... (ì €ìž¥ì²˜: {out_file})")
    y_full, sr = librosa.load(mp3_file, sr=16000)
    
    results_count = 0
    # encoding='utf-8-sig'ë¥¼ ì‚¬ìš©í•˜ì—¬ BOM ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , 
    # strip()ì„ í†µí•´ ì»¬ëŸ¼ëª… ê³µë°± ë¬¸ì œë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    with open(csv_file, "r", encoding="utf-8-sig") as f:
        # ì»¬ëŸ¼ëª…ì˜ ê³µë°±ì„ ìžë™ìœ¼ë¡œ ì œê±°í•˜ë„ë¡ ì„¤ì •
        reader = csv.DictReader(f)
        reader.fieldnames = [name.strip() for name in reader.fieldnames]

        with open(out_file, "w", encoding="utf-8") as fout:
            for row in tqdm(reader, desc="í”¼ì²˜ ì¶”ì¶œ ì¤‘"):
                try:
                    # 'Start Time' í‚¤ê°€ ìžˆëŠ”ì§€ í™•ì¸ í›„ ë°ì´í„° ì¶”ì¶œ
                    st = row.get("Start Time")
                    et = row.get("Stop Time")
                    if st is None or et is None: continue
                    
                    start_sec = float(st)
                    stop_sec = float(et)
                    
                    start_idx = int(start_sec * sr)
                    stop_idx = int(stop_sec * sr)
                    y_segment = y_full[start_idx:stop_idx]
                    
                    if len(y_segment) == 0: continue

                    features = sliding_window_from_buffer(y_segment, sr, window_sec=1.0)
                    record = {
                        "date": date_str,
                        "start": start_sec,
                        "stop": stop_sec,
                        "type": row.get("Type", ""),
                        "speaker": row.get("Speaker", ""),
                        "transcript": row.get("Transcript"),
                        "audio_features": features
                    }
                    fout.write(json.dumps(record, ensure_ascii=False) + "\n")
                    results_count += 1
                except Exception as e:
                    # êµ¬ì²´ì ì¸ ì—ëŸ¬ í™•ì¸ìš©
                    # print(f"ì—ëŸ¬ ë‚´ìš©: {e}") 
                    continue

    print(f"âœ… ì™„ë£Œ: {results_count}ê°œ êµ¬ê°„ ì €ìž¥ ì™„ë£Œ")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--date", required=True, help="ë‚ ì§œ (YYYYMMDD)")
    #parser.add_argument("--out_dir", required=True, help="ê²°ê³¼ë¥¼ ì €ìž¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    args = parser.parse_args()

    process_date(args.date)
    #process_date(args.date, args.out_dir)